# 5.0 神经网络中的三大概念
1. 神经网络训练的最基本的思想就是：先“猜”一个结果，称为预测结果 $a$，看看这个预测结果和事先标记好的训练集中的真实结果 $y$ 之间的差距，然后调整策略，再试一次，这一次就不是“猜”了，而是有依据地向正确的方向靠近。如此反复多次，一直到预测结果和真实结果之间相差无几，亦即 $|a-y|\rightarrow 0$，就结束训练。
2. 在神经网络训练中，我们把“猜”叫做初始化，可以随机，也可以根据以前的经验给定初始值。即使是“猜”，也是有技术含量的。这里，这三大概念就蕴含在神经网络训练的全过程中。
3. 例子：猜数游戏。两个人玩猜数游戏，甲根据乙的反馈调整自己每一次猜测的值。这个例子可以被看作成一个深度学习的模型。
    - 目的：甲猜出乙给出的数字；
    - 初始化：甲猜5；
    - 前向计算：甲每次猜的新数字；
    - 损失函数：乙在根据甲猜的数来和自己心中想的数做比较，得出“大了”或“小了”的结论；（方向：“大”或“小”；程度：“太”、“有点儿”，但是十分的模糊）
    - 反向传播：乙告诉甲“小了”、“大了”；
    - 梯度下降：甲根据乙的反馈中的含义自行调整下一轮的猜测值。
## 反向传播
1. 反向传播（BP, back propagation）是一种用来训练人工神经网络的常见方法，它是一种与最优化方法（如梯度下降法）结合使用的。在训练过程中，神经网络根据输入数据和目标输出计算损失函数，然后通过反向传播算法计算损失函数对每一个参数的梯度。这些梯度信息指导了参数的更新方向，使得损失函数逐渐减小。反向传播算法是目前用来训练人工神经网络的最常用且最有效的算法。
## 梯度下降
1. 梯度下降是迭代法的一种,可以用于求解最小二乘问题(线性和非线性都可以)。在求解机器学习算法的模型参数，即无约束优化问题时，梯度下降（Gradient Descent）是最常采用的方法之一，另一种常用的方法是最小二乘法。在求解损失函数的最小值时，可以通过梯度下降法来一步步的迭代求解，得到最小化的损失函数和模型参数值。
2. 梯度：对于可微的数量场$f(x,y,z)$，以$\left(\dfrac{\partial f}{\partial x},\dfrac{\partial f}{\partial y},\dfrac{\partial f}{\partial z}\right)$为分量的向量场称为$f$的梯度或斜量。
3. 梯度下降法(Gradient Descent)是一个最优化算法，常用于机器学习和人工智能当中用来递归性地逼近最小偏差模型。
## 损失函数
损失函数（Loss Function）或代价函数（Cost Function）是将随机事件或其有关随机变量的取值映射为非负实数以表示该随机事件的“风险”或“损失”的函数，通常用$L(Y,f(x))$表示。在应用中，损失函数通常作为学习准则与优化问题相联系，即通过最小化损失函数求解和评估模型。例如在统计学和机器学习中被用于模型的参数估计（parametric estimation）。损失函数越小，模型的鲁棒性就越好。

# 5.1 神经网络初步

## 神经元模型

1. 神经网络中最基本的单元是神经元模型（neuron）。
2. 在生物神经网络的原始机制中，每个神经元通常都有多个树突（dendrite），一个轴突（axon）和一个细胞体（cell body），树突短而多分支，轴突长而只有一个；在功能上，树突用于传入其它神经元传递的神经冲动，而轴突用于将神经冲动传出到其它神经元，当树突或细胞体传入的神经冲动使得神经元兴奋时，该神经元就会通过轴突向其它神经元传递兴奋。神经元的生物学结构如下图所示。

![1.png](https://i.loli.net/2018/10/17/5bc72cbb6cc11.png)

3. 一直沿用至今的“M-P神经元模型”正是对这一结构进行了抽象，也称“阈值逻辑单元“，其中树突对应于输入部分，每个神经元收到n个其他神经元传递过来的输入信号，这些信号通过带权重的连接传递给细胞体，这些权重又称为连接权（connection weight）。细胞体分为两部分，前一部分计算总输入值（即输入信号的加权和，或者说累积电平），后一部分先计算总输入值与该神经元阈值的差值，然后通过激活函数（activation function）的处理，产生输出从轴突传送给其它神经元。

   其中，输出与激活函数的关系是
   $
   y=f\left(\sum_{i=1}^n w_ix_i-\theta\right)
   $
   M-P神经元模型如下图所示：

![2.png](https://i.loli.net/2018/10/17/5bc72cbb7be44.png)

## 激励函数

1. 激励函数就是使神经元产生兴奋的函数。传递给神经元的输入与权重的乘积的总和，与偏置相加得到的结果（或者减去阈值），会被激励函数转换成用于表示神经元兴奋状态的信号。

2. 如果不使用激励函数，神经元的运算就只是单独地对乘积相加，这样，神经网络也失去了对复杂问题进行处理的能力。

3. 代表性的激励函数如下：
   -  阶跃函数：形如

$$
   y=\left\{\begin{matrix} 
   0,x\le 0\\ 1,x>0
   \end{matrix}\right.
$$

   的函数为阶跃函数。其可以使用0或1来非常简单地表示神经元的兴奋状态，但是其缺点是无法对处于0到1之间的状态进行表示。

   - Sigmoid函数：Sigmoid函数是在0到1之间平滑变化的函数，如$y=\dfrac{1}{1+\exp(-x)}$。该函数变化较为平滑，且可以将0到1之间的情况表示出来。其还比较方便使用微分进行计算。$\dfrac{\mathrm dy}{\mathrm dx}=(1-y)y$，其中，$y=\dfrac{1}{1+\exp(-x)}$。
   
   - tanh函数：即双曲正切函数。$y=\tanh x=\dfrac{\exp(x)-\exp(-x)}{\exp(x)+\exp(-x)}$。它是一个平衡性很好的中心对称的激励函数。
   
   - ReLU函数和Leaky ReLU函数：线性整流函数(Rectified Linear Unit, ReLU)是形如

$$
   y=\left\{\begin{matrix} 
   0,x\le 0\\ x,x>0
   \end{matrix}\right.
$$

   的函数。ReLU 函数较为简单，即使网络层次数量增加也可以比较稳定地进行学习。ReLU 函数的导数为上文提及的阶跃函数。ReLU 函数主要被当作输出层以外的激励函数使用。当$x$为负值时，$\text{Relu}(x)=0$，否则，$\text{Relu}(x)=x$。这又是Relu函数的一大优点。

   而Leaky ReLU函数，是形如

$$
   y=\left\{\begin{matrix} 
   0.01x,x\le 0\\ x,x>0
   \end{matrix}\right.
$$

   的函数。如ReLU函数相比，Leaky ReLU可以有效避免神经元“死亡”的问题。这带来的好处是：在反向传播过程中，对于LeakyReLU激活函数输入小于零的部分，也可以计算得到梯度(而不是像ReLU一样值为0)，这样就避免了上述梯度方向锯齿问题。

   > **神经元“死亡”(Dying ReLU Problem)**
   >
   > ReLU 函数也有缺点。尽管稀疏性可以提升计算高效性，但同样可能阻碍训练过程。通常，激活函数的输入值有一项偏置项(bias)，假设bias变得太小，以至于输入激活函数的值总是负的，那么反向传播过程经过该处的梯度恒为0，对应的权重和偏置参数此次无法得到更新。如果对于所有的样本输入，该激活函数的输入都是负的，那么该神经元再也无法学习，称为神经元”死亡“问题。

   - 恒等函数：形如 $f(x)=x$ 的函数为恒等函数。这里的恒等，指的是函数的表达式在任何情况下都相同。其在处理回归问题时经常被用到。由于输出的范围没有限制且是连续的，所以当需要处理连续数值中存在的回归问题，使用它十分合适。
   
   - SoftMax函数：是用于多类分类问题的激活函数，在多类分类问题中，超过两个类标签则需要类成员关系。对于长度为$K$的任意实向量，Softmax函数可以将其压缩为长度为$K$，值在 $[ 0 , 1 ]$ 范围内，并且向量中元素的总和为1的实向量。其函数形如

$$
   y=\frac{\exp(x)}{\sum\limits_{k=1}^n\exp(x_k)}
$$

   Softmax函数与正常的max函数不同：max函数仅输出最大值，但Softmax函数确保较小的值具有较小的概率，并且不会直接丢弃。我们可以认为它是 $\arg\max$ 函数的概率版本或“soft”版本。Softmax函数的分母结合了原始输出值的所有因子，这意味着Softmax函数获得的各种概率彼此相关。

   Softmax激活函数的特点：

   1. 在零点不可微。
   2. 负输入的梯度为零，这意味着对于该区域的激活，权重不会在反向传播期间更新，因此会产生永不激活的死亡神经元。

# 5.2 感知机与多层网络

## 感知机

感知机是由美国学者 Frank Rosenblatt 在1957年提出来的。感知机是作为神经网络（深度学习）的起源的算法。因此，学习感知机的构造也就是学习通向神经网络和深度学习的一种重要思想。

感知机接收多个输入信号，输出一个信号。这里所说的“信号”可以想象成电流或河流那样具备“流动性”的东西。像电流流过导线，向前方输送电子一样，感知机的信号也会形成流，向前方输送信息。但是，和实际的电流不同的是，感知机的信号只有“流/不流”（1/0）两种取值。这里我们认为0对应“不传递信号”， 1对应“传递信号”。

下图1就是一个接收三个输入信号的感知机的例子。

![img](http://neuralnetworksanddeeplearning.com/images/tikz0.png)

$x_1,x_2,x_3$是输入信号，$y$是输出信号，$w_1,w_2,w_3$是权重（w是weight的首字母）。图中的○称为“神经元”或者“节点”。输入信号被送往神经元时，会被分别乘以固定的权重 $w_ix_i$ 。神经元会计算传送过来的信号的总和，只有当这个总和超过了某个界限值时，才会输出1。这也称为“神经元被激活” 。这里将这个界限值称为阈值，用符号 $\theta$ 表示。

把上述内容用数学式来表示，就是

$$
y=\left\{\begin{matrix} 

0,\text{if }\sum_jw_jx_j\le\theta\\ 1,\text{if }\sum_j w_jx_j>\theta

\end{matrix}\right.
$$

感知机可以轻松地实现逻辑与、或、非运算，只需要满足信号总和和阈值的多种关系，即可实现不同的逻辑门。

感知机权重的学习规则如下：对于训练样本（x，y），当该样本进入感知机学习后，会产生一个输出值，若该输出值与样本的真实标记不一致，则感知机会对权重进行调整，若激活函数为阶跃函数，则调整的方法为（基于梯度下降法）：

对于样本  (x, y) , 其预测值为: 

$$
\hat{\mathrm{y}}=\mathrm{f}\left(\sum_{i=1}^{n} \omega_{i} x_{i}-\theta\right)=\mathrm{f}\left(\sum_{i=1}^{n+1} \omega_{i} x_{i}\right)
$$

其中  $\mathrm{x}_{i+1}=-1$为固定值，均方误差为: $E=\frac{1}{2}(\mathrm{y}-\hat{\mathrm{y}})^{2}$ 。使用梯度下降法寻找最小的均方误差$ \min E $，负的梯度方向为最速下降方向

$$
\frac{\partial E}{\partial \omega_{1}}=-(\mathrm{y}-\hat{\mathrm{y}}) \frac{\partial \hat{\mathrm{y}}}{\partial \omega_{i}}=-(\mathrm{y}-\hat{\mathrm{y}}) \frac{\partial f\left(\sum_{i=1}^{n+1} \omega_{i} x_{i}\right)}{\partial \omega_{i}}
$$

因为函数$f$为阶跃函数, 故有: 

$$
\frac{\partial f\left(\sum_{i=1}^{n+1} \omega_{i} x_{i}\right)}{\partial \omega_{i}}=x_{i}
$$

令下降步长为 $\eta, \eta \in(0,1)$, 则:

$$
\Delta \omega_{i}=-\frac{\partial E}{\partial \omega_{\mathrm{i}}} * \eta=\eta(\mathrm{y}-\hat{\mathrm{y}}) x_{i}
$$

其中 $\eta \in(0,1)$称为学习率，可以看出感知机是通过逐个样本输入来更新权重，首先设定好初始权重（一般为随机），逐个地输入样本数据，若输出值与真实标记相同则继续输入下一个样本，若不一致则更新权重，然后再重新逐个检验，直到每个样本数据的输出值都与真实标记相同。容易看出：感知机模型总是能将训练数据的每一个样本都预测正确，和决策树模型总是能将所有训练数据都分开一样，感知机模型很容易产生过拟合问题。

需注意的是，感知机只有输出层神经元进行激活函数处理，即只拥有一层功能神经元(functional neuron)，其学习能力非常有限。事实上，上述与、或、非问题都是线性可分(linearly separable)的问题，可以证明[Minsky and Papert, 1969]：

1. 若两类模式是线性可分的，即存在一个线性超平面能将它们分开，则感知机的学习过程一定会收敛(converge)而求得适当的权向量$\mathbf{w}=(w_1,w_2,\ldots,w_{n+1})$；
2. 否则感知机学习过程将会发生振荡(Fluctuation)，$\mathbf{w}$难以稳定下来不能求得合适解，例如感知机甚至不能解决异或这样简单的非线性可分问题。

## 多层网络

要解决非线性可分问题，需要考虑使用多层功能神经元，即神经网络。多层神经网络的拓扑结构如下图所示：

![6.png](https://i.loli.net/2018/10/17/5bc72cbb58ec6.png)

在神经网络中，输入层与输出层之间的层称为隐含层或隐层（hidden layer），隐层和输出层的神经元都是具有激活函数的功能神经元。只需包含一个隐层便可以称为多层神经网络，常用的神经网络称为“多层前馈神经网络”（multi-layer feed-forward neural network），该结构满足以下几个特点：

- 每层神经元与下一层神经元之间完全互连
- 神经元之间不存在同层连接
- 神经元之间不存在跨层连接

![7.png](https://i.loli.net/2018/10/17/5bc72cbb47ff8.png)

根据上面的特点可以得知：这里的“前馈”指的是网络拓扑结构中不存在环或回路，而不是指该网络只能向前传播而不能向后传播（下节中的BP神经网络正是基于前馈神经网络而增加了反馈调节机制）。神经网络的学习过程就是根据训练数据来调整神经元之间的“连接权”以及每个神经元的阈值，换句话说：神经网络所学习到的东西都蕴含在网络的连接权与阈值中。

# 5.3 反向传播

##  赫布理论和赫布学习法则

1. 赫布理论：1949年，由唐纳德·赫布提出，又被称为赫布定律（Hebb's rule）、赫布假说（Hebb's postulate）、细胞结集理论（cell assembly theory）等。他如此表述这一理论：

   > 我们可以假定，反射活动的持续与重复会导致神经元稳定性的持久性提升……当神经元A的轴突与神经元B很近并参与了对B的重复持续的兴奋时，这两个神经元或其中一个便会发生某些生长过程或代谢变化，致使A作为能使B兴奋的细胞之一，它的效能增强了。

2. 赫布理论描述了突触可塑性的基本原理，即突触前神经元向突触后神经元的持续重复的刺激，可以导致突触传递效能的增加。基于赫布理论的学习方法被称为赫布型学习。

3. 赫布型学习（赫布学习法则）：是一个无监督学习规则，这种学习的结果是使网络能够提取训练集的统计特性，从而把输入信息按照它们的相似性程度划分为若干类。 这一点与人类观察和认识世界的过程非常吻合，人类观察和认识世界在相当程度上就是在根据事物的统计特征进行分类。 Hebb学习规则只根据神经元连接间的激活水平改变权值，因此这种方法又称为相关学习或并联学习。

4. 公式如下，其中$\Delta w$为连接强度（权重）的变化量，$y_i,y_j$分别表示突触前、后神经元的兴奋程度（输出）。
$$
   \Delta w=\gamma y_iy_j
$$


## Delta学习法则

1. Delta学习法则（Widrow-Hoff Rule, LMS Rule）是于1960年由Widrow和Hoff提出的一种关于神经网络的学习定律，内容如下：

   > 如果输出于正确答案之间的差值越大，则需要设置的权重的修正量也越大；
   >
   > 如果输入越大，则需要设置的权重的修正量也越大。

2. 公式如下：
   
$$
   \Delta w=\eta(y_j-t)y_i
$$

   其中，$t$为正确答案的值，$\eta$为一个被称作“学习系数”的常数。

## Back Propagation 算法

- 由上面可以得知：神经网络的学习主要蕴含在权重和阈值中，多层网络使用上面简单感知机的权重调整规则显然不够用了，BP神经网络算法即误差逆传播算法（Error Back Propagation）正是为学习多层前馈神经网络而设计，BP神经网络算法是迄今为止最成功的的神经网络学习算法。

- 一般而言，只需包含一个足够多神经元的隐层，就能以任意精度逼近任意复杂度的连续函数[Hornik et al.,1989]，故下面以训练单隐层的前馈神经网络为例，介绍BP神经网络的算法思想。

![8.png](https://i.loli.net/2018/10/17/5bc72cbb92ff5.png)

   1. 上图为一个单隐层前馈神经网络的拓扑结构，BP神经网络算法也使用梯度下降法（gradient descent），以单个样本的均方误差的负梯度方向对权重进行调节。

   2. 可以看出：BP算法首先将误差反向传播给隐层神经元，调节隐层到输出层的连接权重与输出层神经元的阈值；接着根据隐含层神经元的均方误差，来调节输入层到隐含层的连接权值与隐含层神经元的阈值。BP算法基本的推导过程与感知机的推导过程原理是相同的，下面给出调整隐含层到输出层的权重调整规则的推导过程：

$$
   E_{k}=\frac{1}{2} \sum_{j=1}^{1}\left(\hat{y_{j}}-y_{j}\right)^{2}
$$

其中，$\hat{y}_{j}=f\left(\sum_{h=1}^{q} w_{h j} b_{h}-\theta_{j}\right)$。故$E_k$是关于$W_{hj}$与$\theta_{j}$的多项式。令$b_{q+1}=-1$，有

$$
   \hat{y_{j}}=f\left(\sum_{n=1}^{q+1} W_{hj}b_{n}\right)
$$

根据链式法则，有
$$
\begin{aligned}\frac{\partial E_{k}}{\partial w_{h}} & =\frac{\partial E_{k}}{\partial \hat{y}_{j}} \cdot \frac{\partial \hat{y}_{j}}{\partial \beta_{j}} \cdot \frac{\partial \beta_{j}}{\partial w_{n j}} \\& =\left(\hat{y_{j}}-y_{j}\right) \cdot f^{\prime}\left(\beta_{j}\right) \cdot b_{h} \\& =\left(\hat{y_{j}}-y_{j}\right) \cdot \frac{1}{1+e^{-\beta_{j}}} \cdot\left(1-\frac{1}{1+e^{-\beta_{j}}}\right) \cdot b_{h} \\& =\left(\hat{y_{j}}-y_{j}\right) \cdot \hat{y_{j}} \cdot\left(1-\hat{y}_{j}\right) \cdot b_{h}\end{aligned}
$$



故$\Delta w_{r j}=-\dfrac{\partial E_{k}}{\partial w_{n j}} \cdot \eta, \eta \in(0,1)$。

所以，有
$$
   \Delta w_{n j}=\eta\left(y_{j}-\hat{y_{j}}\right) \cdot \hat{y_{j}} \cdot\left(1-\hat{y_{j}}\right) \cdot b_{h}
$$


$$
   \Delta \theta_{j}=-\eta\left(y_{j}-\hat{y_{j}}\right) y_{j}\left(1-\hat{y_{j}}\right),(\text{i.e. }b_n=-1)
$$


$$
\Delta v_{i n}=\eta b_{n}\left(1-b_{n}\right) \sum_{j=1}^{l} w_{n j} g_{j} x_{i}
$$


$$
   \Delta r_{n}=-\eta b_{n}\left(1-b_{n}\right) \sum_{j=1}^{l} w_{n j} g_{i}
$$

梯度项：$g_{i}=\hat{y_{j}}\left(1-\hat{y_{j}}\right)\left(y_{j}-\hat{y_{j}}\right)$。

- 学习率$\eta\in(0,1)$控制着沿反梯度方向下降的步长，若步长太大则下降太快容易产生震荡，若步长太小则收敛速度太慢，一般地常把η设置为0.1，有时更新权重时会将输出层与隐含层设置为不同的学习率。BP算法的基本流程如下所示：

![10.png](https://i.loli.net/2018/10/17/5bc72cbb59e99.png)

- BP算法的更新规则是基于每个样本的预测值与真实类标的均方误差来进行权值调节，即BP算法每次更新只针对于单个样例。需要注意的是：BP算法的最终目标是要最小化整个训练集D上的累积误差，即：

$$
   E=\frac{1}{m}\sum_{k=1}^m E_k
$$

如果基于累积误差最小化的更新规则，则得到了累积误差逆传播算法（accumulated error backpropagation），即每次读取全部的数据集一遍，进行一轮学习，从而基于当前的累积误差进行权值调整，因此参数更新的频率相比标准BP算法低了很多，但在很多任务中，尤其是在数据量很大的时候，往往标准BP算法会获得较好的结果。另外对于如何设置隐层神经元个数的问题，至今仍然没有好的解决方案，常使用“试错法”进行调整。

前面提到，BP神经网络强大的学习能力常常容易造成过拟合问题，有以下两种策略来缓解BP网络的过拟合问题：

- 早停：将数据分为训练集与测试集，训练集用于学习，测试集用于评估性能，若在训练过程中，训练集的累积误差降低，而测试集的累积误差升高，则停止训练。
- 引入正则化（regularization）：基本思想是在累积误差函数中增加一个用于描述网络复杂度的部分，例如所有权值与阈值的平方和，其中$\lambda\in(0,1)$用于对累积经验误差与网络复杂度这两项进行折中，常通过交叉验证法来估计。

$$
E=\lambda\frac{1}{m}\sum_{k=1}^m E_k+(1-\lambda)\sum_iw_i^2
$$

# 5.4 梯度下降

## 从自然现象中理解梯度下降

在大多数文章中，都以“一个人被困在山上，需要迅速下到谷底”来举例，这个人会“寻找当前所处位置最陡峭的地方向下走”。这个例子中忽略了安全因素，这个人不可能沿着最陡峭的方向走，要考虑坡度。

在自然界中，梯度下降的最好例子，就是泉水下山的过程：

1. 水受重力影响，会在当前位置，沿着最陡峭的方向流动，有时会形成瀑布（梯度下降）；
2. 水流下山的路径不是唯一的，在同一个地点，有可能有多个位置具有同样的陡峭程度，而造成了分流（可以得到多个解）；
3. 遇到坑洼地区，有可能形成湖泊，而终止下山过程（不能得到全局最优解，而是局部最优解）。

## 梯度下降的数学理解

梯度下降的数学公式：

$$
   \theta_{n+1} = \theta_{n} - \eta \cdot \nabla J(\theta)
$$

其中：

- $\theta_{n+1}$：下一个值；
- $\theta_n$：当前值；
- $-$：减号，梯度的反向；
- $\eta$：学习率或步长，控制每一步走的距离，不要太快以免错过了最佳景点，不要太慢以免时间太长；
- $\nabla$：梯度，函数当前位置的最快上升点；
- $J(\theta)$：函数。

### 梯度下降的三要素

1. 当前点；
2. 方向；
3. 步长。

### 为什么说是“梯度下降”？

“梯度下降”包含了两层含义：

1. 梯度：函数当前位置的最快上升点；
2. 下降：与导数相反的方向，用数学语言描述就是那个减号。

亦即与上升相反的方向运动，就是下降。

<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC1%E6%AD%A5%20-%20%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/img/2/gd_concept.png" ch="500" />

图2-9 梯度下降的步骤

图2-9解释了在函数极值点的两侧做梯度下降的计算过程，梯度下降的目的就是使得x值向极值点逼近。

## 单变量函数的梯度下降

假设一个单变量函数：$J(x)=x^2$，我们的目的是找到该函数的最小值，于是计算其微分：$J'(x) = 2x$。

假设初始位置为：$x_0=1.2$，假设学习率：$\eta=0.3$，则迭代公式为

$$
   x_{n+1} = x_{n} - \eta \cdot \nabla J(x)= x_{n} - \eta \cdot 2x
$$

假设终止条件为 $J(x)<0.01$，迭代过程是：
```
x=0.480000, y=0.230400
x=0.192000, y=0.036864
x=0.076800, y=0.005898
x=0.030720, y=0.000944
```

上面的过程如图2-10所示。

<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC1%E6%AD%A5%20-%20%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/img/2/gd_single_variable.png" ch="500" />

图2-10 使用梯度下降法迭代的过程

## 双变量的梯度下降

假设一个双变量函数：$J(x,y) = x^2 + \sin^2(y)$

我们的目的是找到该函数的最小值，于是计算其微分：

$$
   {\partial{J(x,y)} \over \partial{x}} = 2x
$$


$$
   {\partial{J(x,y)} \over \partial{y}} = 2 \sin y \cos y
$$

假设初始位置为：$(x_0,y_0)=(3,1)$

假设学习率：$\eta = 0.1$

根据公式(1)，迭代过程是的计算公式：

$$
   (x_{n+1},y_{n+1}) = (x_n,y_n) - \eta \cdot \nabla J(x,y)
$$

$$
   = (x_n,y_n) - \eta \cdot (2x,2 \cdot \sin y \cdot \cos y)
$$

根据公式(1)，假设终止条件为 $J(x,y)<0.01$，迭代过程如表2-3所示。

表2-3 双变量梯度下降的迭代过程

|迭代次数|x|y|J(x,y)|
|:-:|:-:|:-:|:-:|
|1|3|1|9.708073|
|2|2.4|0.909070|6.382415|
|...|...|...|...|
|15|0.105553|0.063481|0.015166|
|16|0.084442|0.050819|0.009711|

迭代16次后，$J(x,y)$ 的值为 $0.009711$，满足小于 $0.01$ 的条件，停止迭代。

上面的过程如表2-4所示，由于是双变量，所以需要用三维图来解释。请注意看两张图中间那条隐隐的黑色线，表示梯度下降的过程，从红色的高地一直沿着坡度向下走，直到蓝色的洼地。

表2-4 在三维空间内的梯度下降过程

|观察角度1|观察角度2|
|--|--|
|<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC1%E6%AD%A5%20-%20%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/img/2/gd_double_variable.png">|<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC1%E6%AD%A5%20-%20%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/img/2/gd_double_variable2.png">|

## 学习率η的选择

在公式表达时，学习率被表示为$\eta$。在代码里，我们把学习率定义为`learning_rate`，或者`eta`。针对上面的例子，试验不同的学习率对迭代情况的影响，如表2-5所示。

表2-5 不同学习率对迭代情况的影响

|学习率|迭代路线图|说明|
|:-:|:-:|:-:|
|1.0|<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC1%E6%AD%A5%20-%20%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/img/2/gd100.png" width="500" height="150"/>|学习率太大，迭代的情况很糟糕，在一条水平线上跳来跳去，永远也不能下降。|
|0.8|<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC1%E6%AD%A5%20-%20%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/img/2/gd080.png" width="400"/>|学习率大，会有这种左右跳跃的情况发生，这不利于神经网络的训练。|
|0.4|<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC1%E6%AD%A5%20-%20%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/img/2/gd040.png" width="400"/>|学习率合适，损失值会从单侧下降，4步以后基本接近了理想值。|
|0.1|<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC1%E6%AD%A5%20-%20%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/img/2/gd010.png" width="400"/>|学习率较小，损失值会从单侧下降，但下降速度非常慢，10步了还没有到达理想状态。|

## 梯度计算方法概要

- 假设$\mathbf{w}$为权重，$\mathbf{b}$为偏置，$\mathbf{E}$为误差，则在梯度下降法中，对$w,b$的更新公式为：

$$
   \begin{aligned}
   \mathbf{w} & = \mathbf{w} - \eta \frac{\partial \mathbf{E}}{\partial \mathbf{w}} \\
   \mathbf{b} & = \mathbf{b} - \eta \frac{\partial \mathbf{E}}{\partial \mathbf{b}}
   \end{aligned}
$$

   其中$\eta$为学习率。

- 现在假设由一个三层的神经网络，要对其中各个神经层的梯度进行求解。

   1. 对各个层的认识。三层分别是输入层、隐藏层和输出层，其中隐藏层和输出层都包含偏置和权重。由于输入层只是单纯地将接收到的数据传入给下面的网络层，因此其没有权重和偏置。

   2. 在输出层中，需要根据误差对权重和偏置的梯度进行计算。另外，传递给输出层的输入数据的梯度也同样要根据误差计算。在进行正向传播的过程中，是对网络层的输出进行传播；而在反向传播的过程中，则是对输入的梯度进行传播。

   3. 在中间层中接收这个输入的梯度，根据输入的梯度对权重和偏置的梯度，以及传递给中间层的输入的梯度进行计算。输入的梯度在网络中是从下层往上层进行回溯传递的。关于对输入的梯度进行传播的理由，我们将在稍后进行讲解。

   4. 此外，即使网络层的数量增加到四层以上，通过对输入的梯度进行传播，除了输出层以外，在所有的网络层都可以使用相同的方法对梯度进行计算。因此，只要知道如何在三层的神经网络中对梯度进行求解，那么无论网络的层数如何增加，一样也能够求解。

   5. 接下来使用数学公式对梯度进行求解。根据网络层中所使用的激励函数、损失雨数的种类的不同，对梯度进行计算的方法也多少有些差异，因此我们先对其中通用的部分进行讲解。

      | 网络层 | 下标 | 神经元数量 |
      | :----: | :--: | :--------: |
      | 输入层 |  i   |     l      |
      | 中间层 |  j   |     m      |
      | 输出层 |  k   |     n      |

## 输出层的梯度

- 用$w_{jk}$代表输出层中的权重，$b_k$为偏置，$u_k=\sum w_{jk}x_k+b_k$，则有：

- 权重的梯度

$$
   \partial{w_{jk}}=\dfrac{\partial E}{\partial{w_{jk}}}=\dfrac{\partial E}{\partial u_k}\cdot\dfrac{\partial u_k}{\partial{w_{jk}}}
$$

其中又有$\dfrac{\partial u_k}{\partial{w_{jk}}}=y_j$（展开u项）。
对于$\dfrac{\partial E}{\partial u_k}$，使用链式法则展开，得到（使用输出层的神经元）

$$
   \dfrac{\partial E}{\partial u_k}=\dfrac{\partial E}{\partial y_k}\cdot\dfrac{\partial y_k}{\partial u_k}
$$

对于前者可以使用损失函数的偏微分计算得到，对于后者可以使用激活函数的偏微分计算得到。令

$$
   \delta_k=\dfrac{\partial E}{\partial u_k}=\dfrac{\partial E}{\partial y_k}\cdot\dfrac{\partial y_k}{\partial u_k}
$$

所以，权重和梯度可以表示为

$$
   \partial{w_{jk}}=\delta_k\cdot y_j
$$

- 偏置的梯度也可以使用相同的求解方法。
  
$$
   \partial{b_k}=\dfrac{\partial E}{\partial{b_k}}=\dfrac{\partial E}{\partial u_k}\cdot\dfrac{\partial u_k}{\partial{b_k}}=\delta_k\cdot1.
$$

## 输出层的输入梯度

- 在输出层中，为了提前满足中间层的计算条件，必须提前计算$\partial y_j=\dfrac{\partial E}{\partial y_j}$（中间层的输出梯度，即输出层的输入梯度）。

- 对于$\partial y_j$，有
  
$$
   \partial y_j=\sum_{r=1}^n \frac{\partial E}{\partial u_r}\cdot\frac{\partial u_r}{\partial y_j}
$$

对于后一项，有$\dfrac{\partial u_r}{\partial y_j}=w_{jr}$。所以，有

$$
   \partial y_j=\sum_{r=1}^n \delta_r\cdot w_{jr}
$$

其中，$\delta_r=\dfrac{\partial E}{\partial u_r}$。


## 中间层的梯度

- 在中间层中，和前序内容一样，我们有
  
$$
   \partial{w_{ij}}=\dfrac{\partial E}{\partial{w_{ij}}}=\dfrac{\partial E}{\partial u_j}\cdot\dfrac{\partial u_j}{\partial{w_{ij}}}=\frac{\partial E}{\partial u_j}y_i
$$

接下来，我们计算$\dfrac{\partial E}{\partial u_j}$。使用链式法则展开，得到

$$
   \dfrac{\partial E}{\partial u_j}=\dfrac{\partial E}{\partial y_j}\cdot\dfrac{\partial y_j}{\partial u_j}
$$

其中，右侧的第一部分为中间层的输出梯度，也就是之前求得的$\partial y_j$。第二部分为激活函数的偏微分。令

$$
   \delta_j=\dfrac{\partial E}{\partial u_j}=\partial y_j\cdot\dfrac{\partial y_j}{\partial u_j}
$$

这就可以使用在输出层中计算得到的$\partial y_j$对$\delta j$进行求解，实现了神经网络的回溯。
所以，权重的梯度可以表示为

$$
   \partial{w_{ij}}=\delta_j\cdot y_i
$$

- 对偏置的梯度进行求解：
  
$$
   \partial{b_j}=\dfrac{\partial E}{\partial{b_j}}=\dfrac{\partial E}{\partial u_j}\cdot\dfrac{\partial u_j}{\partial{b_j}}=\delta_j\cdot1
$$

其中，$\delta_j=\dfrac{\partial E}{\partial u_j}$，$\dfrac{\partial u_j}{\partial b_j}=1$。

## 对更多的中间层进行梯度的求解

$$
   \partial{y_i}=\sum_{r=1}^m \delta_r\cdot w_{ir}
$$

## 梯度的计算方法——回归

1. 设置方程：损失函数——平方和误差；中间层的激励函数——Sigmoid函数；输出层的激励函数——恒等函数。
2. 计算方法参见上述内容。

## 梯度的计算方法——分类

1. 设置方程：损失函数——交叉熵误差；中间层的激励函数——Sigmoid函数；输出层的激励函数——Softmax函数。
2. 计算方法参见上述内容。

# 5.5 损失函数

## 损失函数概论

### 概念

在各种材料中经常看到的中英文词汇有：误差，偏差，Error，Cost，Loss，损失，代价......意思都差不多，在本书中，使用“损失函数”和“Loss Function”这两个词汇，具体的损失函数符号用 $J$ 来表示，误差值用 $loss$ 表示。

“损失”就是所有样本的“误差”的总和，亦即（$m$ 为样本数）：

$$
    J = \sum_{i=1}^m \text{loss}_i
$$

我们通常会在根据某个样本的误差调整权重后，计算一下整体样本的损失函数值，来判定网络是不是已经训练到了可接受的状态。

#### 损失函数的作用

损失函数的作用，就是计算神经网络每次迭代的前向计算结果与真实值的差距，从而指导下一步的训练向正确的方向进行。

如何使用损失函数呢？具体步骤：

1. 用随机值初始化前向计算公式的参数；
2. 代入样本，计算输出的预测值；
3. 用损失函数计算预测值和标签值（真实值）的误差；
4. 根据损失函数的导数，沿梯度最小方向将误差回传，修正前向计算公式中的各个权重值；
5. 进入第2步重复, 直到损失函数值达到一个满意的值就停止迭代。

### 机器学习常用损失函数

符号规则：$a$ 是预测值，$y$ 是样本标签值，$loss$ 是损失函数值。

- Gold Standard Loss，又称0-1误差
  
$$
    loss=\begin{cases}
    0 & a=y \\\\
    1 & a \ne y 
    \end{cases}
$$

- 绝对值损失函数

$$
    loss = |y-a|
$$

- Hinge Loss，铰链/折页损失函数或最大边界损失函数，主要用于SVM（支持向量机）中

$$
    loss=\max(0,1-y \cdot a) \qquad y=\pm 1
$$

- Log Loss，对数损失函数，又叫交叉熵损失函数(cross entropy error)

$$
    loss = -[y \cdot \ln (a) + (1-y) \cdot \ln (1-a)]  \qquad y \in \{ 0,1 \}
$$

- Squared Loss，均方差损失函数
  
$$
    loss=(a-y)^2
$$

- Exponential Loss，指数损失函数
  
$$
    loss = e^{-(y \cdot a)}
$$

### 损失函数图像理解

#### 用二维函数图像理解单变量对损失函数的影响

<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC1%E6%AD%A5%20-%20%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/img/3/gd2d.png" />

图3-1 单变量的损失函数图

图3-1中，纵坐标是损失函数值，横坐标是变量。不断地改变变量的值，会造成损失函数值的上升或下降。而梯度下降算法会让我们沿着损失函数值下降的方向前进。

1. 假设我们的初始位置在 $A$ 点，$x=x_0$，损失函数值（纵坐标）较大，回传给网络做训练；
2. 经过一次迭代后，我们移动到了 $B$ 点，$x=x_1$，损失函数值也相应减小，再次回传重新训练；
3. 以此节奏不断向损失函数的最低点靠近，经历了 $x_2,x_3,x_4,x_5$；
4. 直到损失值达到可接受的程度，比如 $x_5$ 的位置，就停止训练。

#### 用等高线图理解双变量对损失函数影响

<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC1%E6%AD%A5%20-%20%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/img/3/gd3d.png" />

图3-2 双变量的损失函数图

图3-2中，横坐标是一个变量 $w$，纵坐标是另一个变量 $b$。两个变量的组合形成的损失函数值，在图中对应处于等高线上的唯一的一个坐标点。$w,b$ 所有不同值的组合会形成一个损失函数值的矩阵，我们把矩阵中具有相同（相近）损失函数值的点连接起来，可以形成一个不规则椭圆，其圆心位置，是损失值为 $0$ 的位置，也是我们要逼近的目标。

这个椭圆如同平面地图的等高线，来表示的一个洼地，中心位置比边缘位置要低，通过对损失函数值的计算，对损失函数的求导，会带领我们沿着等高线形成的梯子一步步下降，无限逼近中心点。

### 神经网络中常用的损失函数

- 均方差函数，主要用于回归

- 交叉熵函数，主要用于分类

二者都是非负函数，极值在底部，用梯度下降法可以求解。

## 均方差函数

MSE - Mean Square Error。

该函数就是最直观的一个损失函数了，计算预测值和真实值之间的欧式距离。预测值和真实值越接近，两者的均方差就越小。

均方差函数常用于线性回归(linear regression)，即函数拟合(function fitting)。公式如下：

单样本：

$$
    loss = {1 \over 2}(z-y)^2
$$

多样本：

$$
    J=\frac{1}{2m} \sum_{i=1}^m (z_i-y_i)^2
$$

### 工作原理

要想得到预测值 $a$ 与真实值 $y$ 的差距，最朴素的想法就是用 $Error=a_i-y_i$。

对于单个样本来说，这样做没问题，但是多个样本累计时，$a_i-y_i$ 可能有正有负，误差求和时就会导致相互抵消，从而失去价值。所以有了绝对值差的想法，即 $Error=|a_i-y_i|$ 。这看上去很简单，并且也很理想，那为什么还要引入均方差损失函数呢？两种损失函数的比较如表3-1所示。

表3-1 绝对值损失函数与均方差损失函数的比较

| 样本标签值  | 样本预测值  |     绝对值损失函数      |        均方差损失函数         |
| :---------: | :---------: | :---------------------: | :---------------------------: |
| $[1,1,1]$ | $[1,2,3]$ | $(1-1)+(2-1)+(3-1)=3$ | $(1-1)^2+(2-1)^2+(3-1)^2=5$ |
| $[1,1,1]$ | $[1,3,3]$ | $(1-1)+(3-1)+(3-1)=4$ | $(1-1)^2+(3-1)^2+(3-1)^2=8$ |
|             |             |      $4/3=1.33$       |          $8/5=1.6$          |

可以看到5比3已经大了很多，8比4大了一倍，而8比5也放大了某个样本的局部损失对全局带来的影响，用术语说，就是“对某些偏离大的样本比较敏感”，从而引起监督训练过程的足够重视，以便回传误差。

### 实际案例

假设有一组数据如图3-3，我们想找到一条拟合的直线。

<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC1%E6%AD%A5%20-%20%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/img/3/mse1.png" ch="500" />

图3-3 平面上的样本数据

图3-4中，前三张显示了一个逐渐找到最佳拟合直线的过程。

- 第一张，用均方差函数计算得到 $Loss=0.53$；
- 第二张，直线向上平移一些，误差计算 $Loss=0.16$，比图一的误差小很多；
- 第三张，又向上平移了一些，误差计算 $Loss=0.048$，此后还可以继续尝试平移（改变 $b$ 值）或者变换角度（改变 $w$ 值），得到更小的损失函数值；
- 第四张，偏离了最佳位置，误差值 $Loss=0.18$，这种情况，算法会让尝试方向反向向下。

<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC1%E6%AD%A5%20-%20%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/img/3/mse2.png" ch="500" />

图3-4 损失函数值与直线位置的关系

第三张图损失函数值最小的情况。比较第二张和第四张图，由于均方差的损失函数值都是正值，如何判断是向上移动还是向下移动呢？

在实际的训练过程中，是没有必要计算损失函数值的，因为损失函数值会体现在反向传播的过程中。我们来看看均方差函数的导数：

$$
    \frac{\partial{J}}{\partial{a_i}} = a_i-y_i
$$

虽然 $(a_i-y_i)^2$ 永远是正数，但是 $a_i-y_i$ 却可以是正数（直线在点下方时）或者负数（直线在点上方时），这个正数或者负数被反向传播回到前面的计算过程中，就会引导训练过程朝正确的方向尝试。

在上面的例子中，我们有两个变量 $w,b$，这两个值的变化都会影响最终的损失函数值的。

我们假设该拟合直线的方程是 $y=2x+3$，当我们固定 $w=2$，把 $b$ 值从 $2$ 到 $4$ 变化时，损失函数值的变化如图3-5所示。

<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC1%E6%AD%A5%20-%20%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/img/3/LossWithB.png" ch="500" />

图3-5 固定 $w$ 时，$b$ 变化时损失函数值的变化

我们假设该拟合直线的方程是 $y=2x+3$，当我们固定 $b=3$，把 $w$ 值从 $1$ 到 $3$ 变化时，损失函数值的变化如图3-6所示。

<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC1%E6%AD%A5%20-%20%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/img/3/LossWithW.png" ch="500" />

图3-6 固定 $b$ 时，$w$ 变化时损失函数值的变化

### 损失函数的可视化

#### 损失函数值的3D示意图

横坐标为 $w$，纵坐标为 $b$，针对每一个$(w,b)$的组合计算出一个损失函数值，用三维图的高度来表示这个损失函数值。下图中的底部并非一个平面，而是一个有些下凹的曲面，只不过曲率较小，如图3-7。

<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC1%E6%AD%A5%20-%20%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/img/3/lossfunction3d.png" ch="500" />

图3-7 $w$ 和 $b$ 同时变化时的损失值形成的曲面

#### 损失函数值的2D示意图

在平面地图中，我们经常会看到用等高线的方式来表示海拔高度值，下图就是上图在平面上的投影，即损失函数值的等高线图，如图3-8所示。

<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC1%E6%AD%A5%20-%20%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/img/3/lossfunction_contour.png" ch="500" />

图3-8 损失函数的等高线图

如果还不能理解的话，我们用最笨的方法来画一张图，代码如下：

```Python
    s = 200
    W = np.linspace(w-2,w+2,s)
    B = np.linspace(b-2,b+2,s)
    LOSS = np.zeros((s,s))
    for i in range(len(W)):
        for j in range(len(B)):
            z = W[i] * x + B[j]
            loss = CostFunction(x,y,z,m)
            LOSS[i,j] = round(loss, 2)
```
上述代码针对每个 $(w,b)$ 组合计算出了一个损失值，保留小数点后2位，放在`LOSS`矩阵中，如下所示：

```
[[4.69 4.63 4.57 ... 0.72 0.74 0.76]
 [4.66 4.6  4.54 ... 0.73 0.75 0.77]
 [4.62 4.56 4.5  ... 0.73 0.75 0.77]
 ...
 [0.7  0.68 0.66 ... 4.57 4.63 4.69]
 [0.69 0.67 0.65 ... 4.6  4.66 4.72]
 [0.68 0.66 0.64 ... 4.63 4.69 4.75]]
```

然后遍历矩阵中的损失函数值，在具有相同值的位置上绘制相同颜色的点，比如，把所有值为0.72的点绘制成红色，把所有值为0.75的点绘制成蓝色......，这样就可以得到图3-9。

<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC1%E6%AD%A5%20-%20%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/img/3/lossfunction2d.png" ch="500" />

图3-9 用笨办法绘制等高线图

此图和等高线图的表达方式等价，但由于等高线图比较简明清晰，所以以后我们都使用等高线图来说明问题。

## 交叉熵损失函数

交叉熵（Cross Entropy）是Shannon信息论中一个重要概念，主要用于度量两个概率分布间的差异性信息。在信息论中，交叉熵是表示两个概率分布 $p,q$ 的差异，其中 $p$ 表示真实分布，$q$ 表示预测分布，那么 $H(p,q)$ 就称为交叉熵：

$$
    H(p,q)=\sum_i p_i \cdot \ln {1 \over q_i} = - \sum_i p_i \ln q_i
$$

交叉熵可在神经网络中作为损失函数，$p$ 表示真实标记的分布，$q$ 则为训练后的模型的预测标记分布，交叉熵损失函数可以衡量 $p$ 与 $q$ 的相似性。

**交叉熵函数常用于逻辑回归(logistic regression)，也就是分类(classification)。**

### 交叉熵的由来

#### 信息量

信息论中，信息量的表示方式：

$$
    I(x_j) = -\ln (p(x_j)) 
$$

$x_j$：表示一个事件

$p(x_j)$：表示 $x_j$ 发生的概率

$I(x_j)$：信息量，$x_j$ 越不可能发生时，它一旦发生后的信息量就越大

假设对于学习神经网络原理课程，我们有三种可能的情况发生，如表3-2所示。

表3-2 三种事件的概论和信息量

| 事件编号 | 事件   | 概率 $p$ | 信息量 $I$         |
| -------- | ------ | ---------- | -------------------- |
| $x_1$  | 优秀   | $p=0.7$  | $I=-\ln(0.7)=0.36$ |
| $x_2$  | 及格   | $p=0.2$  | $I=-\ln(0.2)=1.61$ |
| $x_3$  | 不及格 | $p=0.1$  | $I=-\ln(0.1)=2.30$ |

WoW，某某同学不及格！好大的信息量！相比较来说，“优秀”事件的信息量反而小了很多。

#### 熵

$$
    H(p) = - \sum_j^n p(x_j) \ln (p(x_j))
$$

则上面的问题的熵是：

$$
    \begin{aligned}  
    H(p)&=-[p(x_1) \ln p(x_1) + p(x_2) \ln p(x_2) + p(x_3) \ln p(x_3)] \\\\
    &=0.7 \times 0.36 + 0.2 \times 1.61 + 0.1 \times 2.30 \\\\
    &=0.804
    \end{aligned}
$$

#### 相对熵(KL散度)

相对熵又称KL散度，如果我们对于同一个随机变量 $x$ 有两个单独的概率分布 $P(x)$ 和 $Q(x)$，我们可以使用 KL 散度（Kullback-Leibler (KL) divergence）来衡量这两个分布的差异，这个相当于信息论范畴的均方差。

KL散度的计算公式：

$$
    D_{KL}(p||q)=\sum_{j=1}^n p(x_j) \ln{p(x_j) \over q(x_j)}
$$

$n$ 为事件的所有可能性。$D$ 的值越小，表示 $q$ 分布和 $p$ 分布越接近。

#### 交叉熵

把上述公式变形：

$$
    \begin{aligned}  
    D_{KL}(p||q)&=\sum_{j=1}^n p(x_j) \ln{p(x_j)} - \sum_{j=1}^n p(x_j) \ln q(x_j) \\
    &=- H(p(x)) + H(p,q) 
    \end{aligned}
$$

等式的前一部分恰巧就是 $p$ 的熵，等式的后一部分，就是交叉熵：

$$
    H(p,q) =- \sum_{j=1}^n p(x_j) \ln q(x_j)
$$

在机器学习中，我们需要评估标签值 $y$ 和预测值 $a$ 之间的差距，使用KL散度刚刚好，即 $D_{KL}(y||a)$，由于KL散度中的前一部分 $H(y)$ 不变，故在优化过程中，只需要关注交叉熵就可以了。所以一般在机器学习中直接用交叉熵做损失函数来评估模型。

$$
    loss =- \sum_{j=1}^n y_j \ln a_j
$$

公式7是单个样本的情况，$n$ 并不是样本个数，而是分类个数。所以，对于批量样本的交叉熵计算公式是：

$$
    J =- \sum_{i=1}^m \sum_{j=1}^n y_{ij} \ln a_{ij}
$$

$m$ 是样本数，$n$ 是分类数。

有一类特殊问题，就是事件只有两种情况发生的可能，比如“学会了”和“没学会”，称为 $0/1$ 分类或二分类。对于这类问题，由于$n=2,y_1=1-y_2,a_1=1-a_2$，所以交叉熵可以简化为：

$$
    loss =-[y \ln a + (1-y) \ln (1-a)]
$$

二分类对于批量样本的交叉熵计算公式是：

$$
    J= - \sum_{i=1}^m [y_i \ln a_i + (1-y_i) \ln (1-a_i)]
$$

### 二分类问题交叉熵

把公式10分解开两种情况，当 $y=1$ 时，即标签值是 $1$，是个正例，加号后面的项为 $0$：

$$
    loss = -\ln(a)
$$
横坐标是预测输出，纵坐标是损失函数值。$y=1$ 意味着当前样本标签值是1，当预测输出越接近1时，损失函数值越小，训练结果越准确。当预测输出越接近0时，损失函数值越大，训练结果越糟糕。

当 $y=0$ 时，即标签值是0，是个反例，加号前面的项为0：

$$
    loss = -\ln (1-a)
$$

此时，损失函数值如图3-10。

<img src="https://microsoft.github.io/ai-edu/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/A2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/%E7%AC%AC1%E6%AD%A5%20-%20%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/img/3/crossentropy2.png" ch="500" />

图3-10 二分类交叉熵损失函数图

假设学会了课程的标签值为1，没有学会的标签值为0。我们想建立一个预测器，对于一个特定的学员，根据出勤率、课堂表现、作业情况、学习能力等等来预测其学会课程的概率。

对于学员甲，预测其学会的概率为0.6，而实际上该学员通过了考试，真实值为1。所以，学员甲的交叉熵损失函数值是：

$$
    loss_1 = -(1 \times \ln 0.6 + (1-1) \times \ln (1-0.6)) = 0.51
$$

对于学员乙，预测其学会的概率为0.7，而实际上该学员也通过了考试。所以，学员乙的交叉熵损失函数值是：

$$
    loss_2 = -(1 \times \ln 0.7 + (1-1) \times \ln (1-0.7)) = 0.36
$$

由于0.7比0.6更接近1，是相对准确的值，所以 $loss2$ 要比 $loss1$ 小，反向传播的力度也会小。

### 多分类问题交叉熵

当标签值不是非0即1的情况时，就是多分类了。假设期末考试有三种情况：

1. 优秀，标签值OneHot编码为 $[1,0,0]$；
2. 及格，标签值OneHot编码为 $[0,1,0]$；
3. 不及格，标签值OneHot编码为 $[0,0,1]$。

假设我们预测学员丙的成绩为优秀、及格、不及格的概率为：$[0.2,0.5,0.3]$，而真实情况是该学员不及格，则得到的交叉熵是：

$$
    loss_1 = -(0 \times \ln 0.2 + 0 \times \ln 0.5 + 1 \times \ln 0.3) = 1.2
$$


假设我们预测学员丁的成绩为优秀、及格、不及格的概率为：$[0.2,0.2,0.6]$，而真实情况是该学员不及格，则得到的交叉熵是：

$$
    loss_2 = -(0 \times \ln 0.2 + 0 \times \ln 0.2 + 1 \times \ln 0.6) = 0.51
$$

可以看到，0.51比1.2的损失值小很多，这说明预测值越接近真实标签值（0.6 vs 0.3），交叉熵损失函数值越小，反向传播的力度越小。

### 为什么不能使用均方差做为分类问题的损失函数？

1. 回归问题通常用均方差损失函数，可以保证损失函数是个凸函数，即可以得到最优解。而分类问题如果用均方差的话，损失函数的表现不是凸函数，就很难得到最优解。而交叉熵函数可以保证区间内单调。

2. 分类问题的最后一层网络，需要分类函数，Sigmoid或者Softmax，如果再接均方差函数的话，其求导结果复杂，运算量比较大。用交叉熵函数的话，可以得到比较简单的计算结果，一个简单的减法就可以得到反向误差。

# 5.6 全局最小和局部最小

## 最小

模型学习的过程实质上就是一个寻找最优参数的过程，例如BP算法试图通过最速下降来寻找使得累积经验误差最小的权值与阈值，在谈到最优时，一般会提到局部极小（local minimum）和全局最小（global minimum）。

    * 局部极小解：参数空间中的某个点，其邻域点的误差函数值均不小于该点的误差函数值。
        * 全局最小解：参数空间中的某个点，所有其他点的误差函数值均不小于该点的误差函数值。

![13.png](https://i.loli.net/2018/10/17/5bc72ce2803dc.png)

要成为局部极小点，只要满足该点在参数空间中的梯度为零。局部极小可以有多个，而全局最小只有一个。全局最小一定是局部极小，但局部最小却不一定是全局最小。显然在很多机器学习算法中，都试图找到目标函数的全局最小。梯度下降法的主要思想就是沿着负梯度方向去搜索最优解，负梯度方向是函数值下降最快的方向，若迭代到某处的梯度为0，则表示达到一个局部最小，参数更新停止。因此在现实任务中，通常使用以下策略尽可能地去接近全局最小。

    * 以多组不同参数值初始化多个神经网络，按标准方法训练，迭代停止后，取其中误差最小的解作为最终参数。
        * 使用“模拟退火”技术，这里不做具体介绍。
        * 使用随机梯度下降，即在计算梯度时加入了随机因素，使得在局部最小时，计算的梯度仍可能不为0，从而迭代可以继续进行。

## 深度学习

理论上，参数越多，模型复杂度就越高，容量（capability）就越大，从而能完成更复杂的学习任务。深度学习（deep learning）正是一种极其复杂而强大的模型。

怎么增大模型复杂度呢？两个办法，一是增加隐层的数目，二是增加隐层神经元的数目。前者更有效一些，因为它不仅增加了功能神经元的数量，还增加了激活函数嵌套的层数。但是对于多隐层神经网络，经典算法如标准BP算法往往会在误差逆传播时发散（diverge），无法收敛达到稳定状态。

那要怎么有效地训练多隐层神经网络呢？一般来说有以下两种方法：

- 无监督逐层训练（unsupervised layer-wise training）：每次训练一层隐节点，把上一层隐节点的输出当作输入来训练，本层隐结点训练好后，输出再作为下一层的输入来训练，这称为预训练（pre-training）。全部预训练完成后，再对整个网络进行微调（fine-tuning）训练。一个典型例子就是深度信念网络（deep belief network，简称DBN）。这种做法其实可以视为把大量的参数进行分组，先找出每组较好的设置，再基于这些局部最优的结果来训练全局最优。

- 权共享（weight sharing）：令同一层神经元使用完全相同的连接权，典型的例子是卷积神经网络（Convolutional Neural Network，简称CNN）。这样做可以大大减少需要训练的参数数目。

![14.png](https://i.loli.net/2018/10/17/5bc72ce28d756.png)

深度学习可以理解为一种特征学习（feature learning）或者表示学习（representation learning），无论是DBN还是CNN，都是通过多个隐层来把与输出目标联系不大的初始输入转化为与输出目标更加密切的表示，使原来只通过单层映射难以完成的任务变为可能。即通过多层处理，逐渐将初始的“低层”特征表示转化为“高层”特征表示，从而使得最后可以用简单的模型来完成复杂的学习任务。

传统任务中，样本的特征需要人类专家来设计，这称为特征工程（feature engineering）。特征好坏对泛化性能有至关重要的影响。而深度学习为全自动数据分析带来了可能，可以自动产生更好的特征。